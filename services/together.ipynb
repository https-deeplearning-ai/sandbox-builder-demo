{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7748736e-73e2-4036-ab3f-b4a72e6a0aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "from openai import OpenAI, DefaultHttpxClient\n",
    "import httpx\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "def get_proxy_url():\n",
    "    return os.environ.get(\"TOGETHER_BASE_URL\", \"https://api.together.xyz/\")\n",
    "\n",
    "def get_proxy_headers():\n",
    "    return {\"Authorization\": os.environ.get(\"TOGETHER_API_KEY\", \"xyz\")}\n",
    "\n",
    "def get_openai_key():\n",
    "    return os.environ.get(\"TOGETHER_API_KEY\", \"xyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c1df3-da4c-4fc8-9097-787db0325382",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = get_proxy_url() # If using together endpoint, add it here https://api.together.xyz/\n",
    "\n",
    "# Custom transport to bypass SSL verification. This is only needed if using our proxy. Otherwise you can ignore it.\n",
    "transport = httpx.HTTPTransport(local_address=\"0.0.0.0\", verify=False)\n",
    "\n",
    "# Create a DefaultHttpxClient instance with the custom transport\n",
    "http_client = DefaultHttpxClient(transport=transport, headers=get_proxy_headers())\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key = get_openai_key(), # Set any as our proxy does not use it. Set the together api key if using the together endpoint.\n",
    "    base_url=base_url, \n",
    "    http_client=http_client, # ssl bypass to make it work via proxy calls, remove it if running with together.ai endpoint \n",
    ")\n",
    "\n",
    "messages = [\n",
    "    {'role': 'user', 'content': 'Hello, who won the FIFA world cup in 2018?'},\n",
    "    {'role': 'assistant', 'content': 'France won the 2018 FIFA World Cup.'},\n",
    "    {'role': 'user', 'content': 'Who was the captain?'}\n",
    "]\n",
    "response = client.chat.completions.create(messages = messages, model =\"meta-llama/Llama-3.2-3B-Instruct-Turbo\")\n",
    "pprint(response.choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b73d98-2c1f-4c55-bc7f-b462fc22d3cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
